###############################################
# Second Brain Environment Configuration (.env)
#
# Copy this file to .env and fill in values.
# Only include what you use. Unset values are safe.
###############################################

###############################################
# OpenAI (OCR and/or Embeddings)
###############################################
# Required if you want to use:
# - OpenAI Vision OCR (ocr.engine = "openai")
# - OpenAI Embeddings provider (embeddings.provider = "openai")
OPENAI_API_KEY=your-openai-api-key-here

# Optional: tweak OCR prompt model via settings.json
# (Use CLI or GUI Settings to change models and rate limits.)
# Examples (not read from env):
#   ocr.model = "gpt-5"
#   embeddings.openai_model = "text-embedding-3-small"

###############################################
# Context7 (optional docs integration)
###############################################
# Enable in Settings Panel â†’ Context7 or settings.json
# If set, CLI commands under `second-brain docs ...` will be available.
CONTEXT7_API_KEY=your-context7-api-key-here

###############################################
# Hugging Face (optional)
###############################################
# DeepSeek MLX downloads the model from Hugging Face on first run.
# Public models typically work without a token, but if you have a token
# you can set it here to increase reliability.
#HUGGINGFACE_HUB_TOKEN=hf_...

###############################################
# Notes
###############################################
# - DeepSeek (MLX) requires no API keys; it runs locally on Apple Silicon.
# - Grant macOS Screen Recording permission to your Terminal and to the
#   Python binary inside your virtualenv for capture to work.
